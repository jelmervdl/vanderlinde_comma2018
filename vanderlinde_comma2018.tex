\documentclass{IOS-Book-Article}

% gb4e is buggy
\makeatletter
\def\new@fontshape{}
\makeatother

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathptmx}
% \usepackage{caption} % for \figsentence
\usepackage{subcaption} % for subfigure
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage{syntax} % for grammar environment
\usetikzlibrary{arrows.meta,positioning,patterns}
\usepackage{hyperref} % for urls
\usepackage{gb4e}

\newcommand{\figsentence}[1]{\\{\sffamily{}#1}}

\tikzset{
	x/.style={{Rays[]}},
	-x/.style={-{Rays[]}},
	xx/.style={Rays[]}-{Rays[]},
	box/.style={draw,rectangle,align=center},
	assumed/.style={pattern=crosshatch dots,pattern color=gray},
	every new ->/.style={shorten >=1pt}
}

\begin{document}

	\begin{frontmatter}

		\title{Arguments that can be understood \\by humans and by computers}

		\author{Jelmer VAN DER LINDE, Bart VERHEIJ}

		\address{Artificial Intelligence, University of Groningen}

		\begin{abstract}
	Good argumentation technology requires that humans and computers understand each other's arguments.
	But notwithstanding significant research progress, meeting this requirement remains hard to realize. Formal models underlying argumentation software can be hard to interpret for people (cf. the intricacies of research on argumentation formalisms), and computers can have a hard time understanding natural language arguments made by humans (cf. the complexity of argument mining research).

	In this paper, we develop a restricted argumentation model that is equally understandable for humans and for computers. Concretely, we realize the model in a natural language format and in a formal argument format, visualized as diagrams. It is our strategy to work from the ground up: starting from simple structures gradually moving to more complex structures. We choose this strategy in order to optimize the tractability of successes and resolvability of hurdles. In the restricted argumentation model proposed in this paper we focus on arguments for and against elementary conclusions, and on the rules (warrants, generalizations) underlying them. For evaluating our proposal, we discuss syllogisms and Toulmin arguments.

	The core model of argumentation that we discuss is relevant for formal research on argumentation, since it focuses on argument structure that can be expressed in a computationally understandable natural language form; the core is relevant for argument mining research, since it presents a restricted natural language setting of which the formal structure is computationally understandable.

		\end{abstract}

		\begin{keyword}
		Argument diagrams, argument mining, natural language processing, Toulmin
		\end{keyword}

	\end{frontmatter}

\section{Introduction}
Human communicate and share their knowledge and understanding of their world by arguing with each other. If computers and humans could have a shared argumentation process, they could understand each other better.

\paragraph{Current}
Argumentation and artificial intelligence~\cite{vanEemerenEtal2014ch11}

\paragraph{Non-formal and formal argumentation theory}
\cite{vanEemerenEtal2014,vanEemerenVerheij2017}

Walton started with documenting common structures~\cite{waltonReedMacagno2008} used in argumentation, marking their elements. Note that not all slots of these schemas can always be filled in based on the often terse argumentative texts. Walton's argument schemas also propose critical questions. Walton, and many others, defined such schemas based on the arguments they encountered. Consequently, there is no complete set of all schemas. The schemas are now often used for annotating the relation between parts of arguments, either automatically or using manual annotation.

Argumentation software~\cite{kirschnerEtal2003,verheij2007,scheuerEtal2010,noroozi2012argumentation}

\paragraph{Argument mining}
\cite{moens2017,peldszus2013argument,lippi2016argumentation,mochales2011argumentation}

RST and argumentation schemas offer ways to add structure to arguments in text. Automating this step is the practise of discourse analysis. Approaches to discourse analysis usually aim at identifying various different types of discourse relations. However, we are only interested in a subset of such relations, namely those relevant for argumentation structure parsing. This smaller task is often referred to as Argument Mining~\cite{stabGurevych2017} and this task generally consists consists of multiple subtasks~\cite{lippi2016argumentation}:

\paragraph{Identification} The parts of text that are argumentative â€“- that may contain arguments -- need to be identified: In many texts only certain sentences or paragraphs of the text are argumentative; the rest may be informative, for example providing context. In it's essence this is a binary classification task. Some approaches combine this task with the next and directly detect and classify the argument components~\cite{stabGurevych2017}. In this case the classifier is also tasked with detecting the type of component (e.g. conclusion, minor or major premise, etcetera depending on the structural model used.)

\paragraph{Segmentation} The identified parts need to be split into segments -- the task of component boundary detection -- where each segment may be a component in the final argument representation. Assuming that in a text about a court case the paragraphs containing the ruling and the reasoning behind it are identified, then this step splits that part into components (called argumentative discourse units~\cite{cohen1987} or elementary discourse units~\cite{saintDizier2012}) that can then be identified as the conclusion, premises, etc. This, again, is a classification task. This is implemented as a data-driven search for cue phrases (i.e. the words `because', `unless', but also words, word phrases and punctuation that are less explicit, or a complete analysis of the semantic structure) that indicate relations between text spans~\cite{mochales2011argumentation,saintDizier2012,lawrenceReed2015,stabGurevych2017}.

\paragraph{Prediction} The relations between the identified components need to be predicted. In this task the components are connected to each other to form the structure of the argument. This is the most challenging task as it requires insight in the meaning of a component to determine whether a premise component supports a certain claim component or whether it is related to another claim component. Some approaches also approach this as a binary classification task, testing each of the claim components in a certain defined order~\cite{cohen1987}. Others have a set of hand-coded rules that function as heuristic~\cite{saintDizier2012}. Another approach is to create a model that can determine the likeliness that two components are related and construct multiple scenarios to finally select the best overall scenario. Often knowledge about the domain is used to help in this task. For example, for some texts, such as procedures or didactic text, it can be assumed that a claim is always followed by one or more premises supporting that claim. In juristic texts certain marker words may signal the relations between components.

Most approaches are based on text which has been annotated using RST and a predefined set of schemas. The rules used in the three subtasks are, either by hand or automatically, derived from these previously annotated texts to create a model which can apply the same annotation to new texts.



Toumin's model~\cite{toulmin1958}
Toulmin's influence~\cite{verheij2009}

\paragraph{Our idea}
Our approach to understanding argumentative texts uses the more abstract structure \cite{peldszus2013argument} and we define a grammar for each of the occurring patterns in this abstract argument structure. From this grammar we develop a language for writing argumentative texts. The language itself is a limited subset of English.

\paragraph{Goals}
Support and attack relations between arguments, warranted support in the form of general rules that support the step from premise to conclusion (i.e. major premise in syllogism). The ability to combine sentences to counter the need to restate premises (i.e. allow recursion). Anaphora resolution to avoid the need to restate the subjects. Enthymeme resolution to avoid the need to state many premises at all. 

\paragraph{Results}
For each of the basic building blocks for formal argumentation we define how these occur in our language, and how they can be differentiated form each other.

We implement these building blocks and their grammars into a larger grammar which allows us to create argumentative texts of multiple sentences. This language, the human argument structure language, or HASL for short, is explored in two variants.

We then test our implementation using the following examples:
\begin{exe}
	\ex\label{ex:socrates} Socrates is mortal because he is a man and men are mortal.
	\ex\label{ex:tweety} Tweety can fly because Tweety is a bird and birds can fly but Tweety is a penguin and penguins can not fly.
	\ex\label{ex:light} The object is red because the object appears red to me but it is illuminated by a red light.~\cite{pollock1987}
	\ex\label{ex:toulmin} Harry is a British subject because Harry was born in Bermuda and a man born in Bermuda is a British subject because of the following statutes and legal provisions but Harry has become a naturalized American.~\cite{toulmin1958}
\end{exe}

\paragraph{HASL/0}
Our first experiment is HASL/0, which implements a grammar for combining the building blocks by restating premises in multiple sentences. Each of the building blocks yields its own partial argument structure, which are merged at the sentence level to form the complete argument. This implementation does a complete parse of the premises themselves as well to differentiate between major and minor premises.

This first iteration of HASL is not a very human argument language. The need to restate premises as the only way to compose a larger argument is not ideal, and in many cases we much rather use conjunctives to compose more complex sentences. Other typically human phenomena such as the use of enthymemes and anaphora in argumentation is also not taken into account.

\paragraph{HASL/1}
We create a second iteration, HASL/1, which expands upon HASL/0 in the following ways:

The grammar allows for nested argument structures: A premise that occurs on the right side of `because' can itself be the conclusion of a different part of the argument in the same sentence.

We implement a form of enthymeme resolution. Enthymemes, the occurrence of premises that are part of an argument but are not explicitly stated, occur often in natural language \cite{walton2005,reedRowe2004}. By filling in these missing premises in our argument graph we can make the right support or attack connections between premises, also when the targeted premise is not explicitly stated. We do this by treating building block around the attack and support relations as small syllogisms, and reconstruct the missing minor or major premise. The parsing of premises themselves, which is a part of HASL/1, provides the information necessary for the reconstruction.

We also implement pronominal anaphora resolution \cite{hobbs1978}. In HASL/1 premises that are the same are merged into a premise in our argument structure, and in HASL/1 we determine whether two premises are the same by comparing their text. When this text contains references to other parts of the argument, for example if the premise is `he has wings', we should also check whether `he' refers to the same object. Otherwise, premises that look the same but don't exactly mean the same are merged. Anaphora resolution helps us check this. By implementing this as part of the premise parser the reconstruction step of the enthymeme resolution can also profit from it.

\paragraph{Relevance}
HASL implements a form of argument mining, but ignores the difficult steps of being able to parse all of the English language. This allows us to explore what a complete understanding of the argumentative text entails, which argument mining is not yet able to explore \cite{stabGurevych2017}.

The implementations of HASL presented here can be used to gain a better understanding of complicated arguments, where there are many premises that interact with each other. Anaphora and enthymeme resolution help with further understanding of the argument.

The language of HASL itself can be used to a new type of interface to the reasoning process of computer programs, allowing for the explanation of the reasoning behind a conclusion, or even for interactive partaking.

\section{Formal argument structure and its natural language expression}
The structure in arguments is made explicit by drawing it using boxes and arrows.

\paragraph{Pros and cons} 

Support relations between premises (\autoref{fig:support}) are the basis of argumentation: These indicate a reason to come to a certain conclusion.

Attack relations (\autoref{fig:attack}) indicate that a premise is, or has at some moment in the argumentative text been, disputed.

Essentially there ware three ways a premise can attack another premise: either by directly attacking it by giving the counter-premise (which states the opposite, \autoref{fig:mutual}), or by attacking the reasoning behind the conclusion. This in turn can be done by attacking either the premises supporting the reasoning (undermining) or the reasoning itself (undercutting, \autoref{fig:undercutter}).

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {$A$};
			\node[box] (pre) at (0, -1) {$B$};
			\draw[->] (pre) to (con);
		\end{tikzpicture}
		\figsentence{$A$ because $B$.}
		\caption{Support}
		\label{fig:support}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {$A$};
			\node[box] (att) at (0, -1) {$B$};
			\draw[-x] (att) to (con);
		\end{tikzpicture}
		\figsentence{$A$ but $B$.}
		\caption{Attack}
		\label{fig:attack}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {$A$};
			\node[box] (att) at (0, -1) {$\neg A$};
			\draw[xx] (att) to (con);
		\end{tikzpicture}
		\figsentence{$A$. $\neg A$.}
		\caption{Mutual attack}
		\label{fig:mutual}
	\end{subfigure}
	\caption{Pros and Cons}
	\label{fig:proscons}
\end{figure}


\paragraph{Conjunctions and negation}

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {$A$};
			\node[box] (per1) at (-.5,-1) {$B$};
			\node[box] (per2) at (.5,-1) {$C$};
			\draw[->] (per1) -- ++(0,.4) -| (con);
			\draw[->] (per2) -- ++(0,.4) -| (con);
		\end{tikzpicture}
		\figsentence{$A$ because $B$ and $C$.}
		\caption{Linked/Cooperative support}
		\label{fig:cooperative}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {$A$};
			\node[box] (per1) at (-.5,-1) {$B$};
			\node[box] (per2) at (.5,-1) {$C$};
			\draw[->] (per1) -- ++(0,.4) -| ([xshift=-0.1cm]con.south);
			\draw[->] (per2) -- ++(0,.4) -| ([xshift=0.1cm]con.south);
		\end{tikzpicture}
		\figsentence{$A$ because $B$ and because $C$.}
		\caption{Multiple/Independent support}
		\label{fig:independent}
	\end{subfigure}
	\begin{subfigure}[b]{.3\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {$A$};
			\node[box] (per1) at (0,-1) {$B$};
			\node[box] (per2) at (0,-2) {$C$};
			\draw[->] (per2) -> (per1);
			\draw[->] (per1) -> (con);
		\end{tikzpicture}
		\figsentence{$A$ because $B$ because $C$.}
		\caption{Chained support/Recursion}
		\label{fig:chained}
	\end{subfigure}
	\caption{Conjunctions}
\end{figure}

Rebuttal only occurs when both $A$ and $\neg A$ occur as premise in the argument, otherwise we drawn them as just an attacking premise. $A$ and $\neg A$ may occur in separate sentences or separate parts of the argument.

Finding out whether $\neg A$ occurs in an argument can be challenging, as for example Tweety being a cat would also imply that Tweety is not a bird. However, for this inference step to take place knowledge about dogs and cats is necessary. (And that is outside the scope of this work for now.)

\paragraph{Recursion}

Only context can be used to disambiguate between these two. We circumvent this by not allowing conjunctions to be the topmost elements of the argument. Each sentence in an argument starts with a conclusion, either followed by pros and cons or not. No a and b at the top.

\paragraph{Rules, warrants, generalizations}

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {$A$};
			\node[box] (war) at (1, -1.5) {$C$};
			\node[box] (pre) at (0, -3) {$B$};
			\node[coordinate] (w) at (0, -1.5) {};
			\draw[->] (pre) -- (w) -> (con);
			\draw[->] (war) -> (w);
		\end{tikzpicture}
		\figsentence{$A$ because $B$ and $C_{maj}$.}
		\caption{Warranted support}
		\label{fig:warrantedsupport}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {$A$};
			\node[box] (war) at (1, -1.5) {$C$};
			\node[box] (pre) at (0, -3) {$B$};
			\node[coordinate] (w) at (0, -1.5) {};
			\draw[-x] (pre) -- (w) -> (con);
			\draw[->] (war) -> (w);
		\end{tikzpicture}
		\figsentence{$A$ but $B$ and $C_{maj}$.}
		\caption{Warranted attack}
		\label{fig:warrantedattack}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {$A$};
			\node[box] (war) at (1, -2) {$C$};
			\node[box] (pre) at (0, -3) {$B$};
			\node[box] (und) at (1, -1) {$D$};
			\node[coordinate] (u) at (0, -1) {};
			\node[coordinate] (w) at (0, -2) {};
			\draw[->] (pre) -- (w) -- (u) -> (con);
			\draw[->] (war) -> (w);
			\draw[-x] (und) -> (u);
		\end{tikzpicture}
		\figsentence{$A$ because $B$ and $C_{maj}$ but $D$.}
		\caption{Undercutter}
		\label{fig:undercutter}
	\end{subfigure}
	\caption{Support using rules and attack thereof}
\end{figure}

\paragraph{Complications:}

\paragraph{Anaphora resolution}
The premises in the boxes are self-contained: they can not refer to each other using pronouns. In (argumentative) text they can because of the word order, but in a diagram the word order is lost. Therefore we should try to avoid the occurrence of pronouns in the boxes.

\paragraph{Enthymemes}
Parts of the argument are unstated: premises assumed to be known and accepted by all parties are not communicated (or not communicated because they are weak and the speaker does not want to wake sleeping dogs). However, these unstated premises can be supported and attacked. In the diagram, they have to be drawn in order for them to be able to supported or attacked. Hence we need to reconstruct and draw them.

\section{Pros, cons, rules: HASL/0}
\input{hasl0}

\section{Recursion, anaphora and enthymemes: HASL/1}
\input{hasl1}

\section{Evaluation: syllogisms and Toulmin arguments}

\begin{exe}
	\ex Tweety can fly because birds can fly but Tweety is a penguin.

	\ex Harry is a British subject because Harry is a man born in Bermuda but Harry has become naturalized.
\end{exe}

\begin{figure}[ht!]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {Tweety can fly};
			\node[box] (min) at (0,-3) {Tweety is a bird};
			\node[box] (maj) at (2,-1) {Birds can fly};
			\node[box] (und) at (2.5,-2) {Tweety is a penguin};
			\node[coordinate] (smaj) at (0,-1) {};
			\node[coordinate] (sund) at (.5,-1) {};
			\node[coordinate] (cund) at (.5,-2) {};
			
			\draw[->] (min) -- (smaj) -| (con);
			\draw[->] (maj) -- (sund) -> (smaj);
			\draw[-x] (und) -- (cund) -> (sund);
		\end{tikzpicture}
		\caption{First interpretation}
	\end{subfigure}

	\begin{subfigure}[b]{\textwidth}
		\centering
		\begin{tikzpicture}
			\node[box] (con) at (0,0) {Tweety can fly};
			\node[box] (min) at (0,-3) {Tweety is a bird};
			\node[box] (maj) at (2,-2) {Birds can fly};
			\node[box] (att) at (2.5,-1) {Tweety is a penguin};
			\node[coordinate] (smaj) at (0,-2) {};
			
			\draw[->] (min) -- (smaj) -| (con);
			\draw[->] (maj) -> (smaj);
			\draw[-x] (att) -| ([xshift=.5cm]con.south);
		\end{tikzpicture}
		\caption{Second interpretation}
	\end{subfigure}
	\figsentence{Tweety can fly because Tweety is a bird and birds can fly but Tweety is a penguin.}
	\caption{Argument diagram from HASL/0}
\end{figure}

\begin{figure}[ht!]
	\centering
	\begin{tikzpicture}
		\node[box] (con) at (0,0) {Harry is a British subject};
		
		\node[box,text width=3cm] (pcon) at (-1.75,-3) {Harry has become naturalized}; % datum
		\node[box,assumed,text width=3cm] (wcon) at (-4,-1.5) {Something is not a British subject if something has become naturalized}; % warrant
		\node[coordinate] (scon) at (-1.75, -1.5) {}; % warrant -> (datum -> concl)
		\node[coordinate] (ccon) at (-1.75, -1) {}; % budge in (datum -> concl) arrow
		
		
		\node[box,text width=3cm] (ppro) at (1.75,-3) {Harry is a man born in Bermuda};
		\node[box,assumed,text width=3cm] (wpro) at (4,-1.5) {A man born in Bermuda is a British subject};
		\node[coordinate] (spro) at (1.75, -1.5) {};
		\node[coordinate] (cpro) at (1.75,-1) {};
		
		\draw[-x] (pcon) -- (scon) -- (ccon) -| ([xshift=-.5cm]con.south);
		\draw[->] (ppro) -- (spro) -- (cpro) -| ([xshift=.5cm]con.south);
		\draw[->] (wcon) -> (scon);
		\draw[->] (wpro) -> (spro);
	\end{tikzpicture}
	\figsentence{Harry is a British subject because Harry is a man born in Bermuda but Harry has become naturalized.}
	\caption{Argument diagram from HASL/1. Shaded boxes are reconstructed major premises.}
\end{figure}


\section{Discussion of related research}

Just adding the assumed missing claims from enthymemes to the argument may not be what the original author of the argument intended. The meaning or weight may become distorted, or it may become clear that the incomplete argument was, after being completed, a bad argument. \cite{waltonReed2005}. 

\begin{table}
	\begin{tabular}{l|ll|}
		& HASL/0 & HASL/1  \\
		\hline
		Support & yes & yes \\
		Attack & yes & yes \\
		Schema recognition & no & via enthymeme resolution \\
		Schema extraction & no & yes
	\end{tabular}
\end{table}

\section{Conclusion}


%
%Diagramming tools (Araucaria, Reason!Able, ArguMed)
%
%Text analysis assistants (Araucaria)
%
%Argument mining
%
%Logical languages (with evaluation)
%
%
%\section{Translating natural language arguments to argument diagrams, and back}
%
%Description of how it all works
%
%(Elementary, representative examples)
%
%\section{Toulmin's diagram}
%
%
%\section{Assessment}
%
%Interesting examples
%
%Things that go wrong!



\bibliographystyle{plain}
\bibliography{cumulative}

\end{document}

