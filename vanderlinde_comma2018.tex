\documentclass{IOS-Book-Article}

% gb4e is buggy
\makeatletter
\def\new@fontshape{}
\makeatother

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathptmx}
% \usepackage{caption} % for \figsentence
\usepackage{subcaption} % for subfigure
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usepackage{syntax} % for grammar environment
\usetikzlibrary{arrows.meta,positioning,patterns}
\usepackage{hyperref} % for urls
\usepackage{gb4e}

\newcommand{\figsentence}[1]{\\{\sffamily{}#1}}

\tikzset{
	x/.style={{Rays[]}},
	-x/.style={-{Rays[]}},
	xx/.style={Rays[]}-{Rays[]},
	box/.style={draw,rectangle,align=center},
	assumed/.style={pattern=crosshatch dots,pattern color=gray},
	every new ->/.style={shorten >=1pt}
}

\begin{document}

	\begin{frontmatter}

		\title{Arguments that can be understood \\by humans and by computers}

		\author{Jelmer VAN DER LINDE, Bart VERHEIJ}

		\address{Artificial Intelligence, University of Groningen}

		\begin{abstract}
	Good argumentation technology requires that humans and computers understand each other's arguments.
	But notwithstanding significant research progress, meeting this requirement remains hard to realize. Formal models underlying argumentation software can be hard to interpret for people (cf. the intricacies of research on argumentation formalisms), and computers can have a hard time understanding natural language arguments made by humans (cf. the complexity of argument mining research).

	In this paper, we develop a restricted argumentation model that is equally understandable for humans and for computers. Concretely, we realize the model in a natural language format and in a formal argument format, visualized as diagrams. It is our strategy to work from the ground up: starting from simple structures gradually moving to more complex structures. We choose this strategy in order to optimize the tractability of successes and resolvability of hurdles. In the restricted argumentation model proposed in this paper we focus on arguments for and against elementary conclusions, and on the rules (warrants, generalizations) underlying them. For evaluating our proposal, we discuss syllogisms and Toulmin arguments.

	The core model of argumentation that we discuss is relevant for formal research on argumentation, since it focuses on argument structure that can be expressed in a computationally understandable natural language form; the core is relevant for argument mining research, since it presents a restricted natural language setting of which the formal structure is computationally understandable.

		\end{abstract}

		\begin{keyword}
		Argument diagrams, argument mining, natural language processing, Toulmin
		\end{keyword}

	\end{frontmatter}

\section{Introduction}
Human communicate and share their knowledge and understanding of their world by arguing with each other. If computers and humans could have a shared argumentation process, they could understand each other better.

\paragraph{Current}
The structure of arguments has been analysed since Aristotle, trying to identify, understand and formalize the workings and structure of arguments which we so effortlessly use every day.

Argumentation, from the perspective or Artificial Intelligence, has focussed mainly on the structure and evaluation of arguments: is this claim true, given these arguments either in favour or opposed it~\cite{vanEemerenEtal2014ch11}.

\paragraph{Non-formal and formal argumentation theory}
Arguments occur in every form of human communication, in dialogue, monologue, explicitly written or almost subliminally implied while conveying information in any form. What all these forms do share is the concept of claims that are made, and that are attacked or supported by other claims, either in the forms of reasoning, or examples, or counter-examples. Formalising this structure is challenging, and the various approaches vary in their focus and formalism\cite{vanEemerenEtal2014,vanEemerenVerheij2017}. For example, Aristotle's syllogism created the dichotomy between minor and major premises, where the major premise serves as a generalized case (i.e. birds can fly) and the minor premise argues that this generalization is applicable (i.e. Tweety is a bird), and thus the conclusion is valid (i.e. Tweety can fly.).

\paragraph{Toulmin's model}
Toulmin\cite{toulmin1958} in a sense continues this work, formalising not only the minor and major premise and conclusion (which roughly translate to his datum, warrant and conclusion) but also dictates which additional elements should be present in a well formulated argument, and what outside of syllogisms the role of a warrant should be: each inference, i.e. each claim supporting a conclusion should be defensible by a warrant, a generalization why this conclusion may be concluded given the supporting datum. This generalization in turn should also be based in evidence, or in logic; it should be supported by a backing. Furthermore, the generalization almost always comes with a qualifier: how certain it is that the generalization is applicable in this situation, which range includes an analytical `all' in claims such as `all penguins are birds' to a statistical `most' in `most swans are white'. And last but not least the option for attack of a conclusion (i.e. a counter-argument) becomes part of the argument, uniting both support and attack in the same model. Toulmin's model of an argument dictates what may elements may be expected in an argument, either explicitly stated or answerable when asked. The elements described in this model form the basis for more formal approaches\cite{verheij2009}.

\paragraph{Walton argument schemas}
Walton started with documenting common structures~\cite{waltonReedMacagno2008} used in argumentation, marking their elements. In a sense, this these schemas extend the formalisation of Toulmin's warrant, and extend the idea of Toulmin's model to more specific arguments in general: Walton's argument schemas also propose critical questions. Walton, and many others, defined such schemas based on the arguments they encountered. Consequently, there is no complete set of all schemas. The schemas are now often used for annotating the relation between parts of arguments, either automatically or using manual annotation.

\paragraph{Argument mining}
With the availability of large corpora of written and annotated text\cite{lawrenceReed2015} and advances in natural language processing, as well as the drive to automate the extraction of computer-understandable information, the challenge of argument mining has thrived. \cite{moens2017,peldszus2013argument,lippi2016argumentation,mochales2011argumentation}

This extraction process of information is the practise of discourse analysis. Approaches to discourse analysis usually aim at identifying various different types of discourse relations. However, we are only interested in a subset of such relations, namely those relevant for argumentation structure parsing. This smaller task is often referred to as Argument Mining~\cite{stabGurevych2017} and this task generally consists consists of multiple subtasks~\cite{lippi2016argumentation}:

\paragraph{Identification} The parts of text that are argumentative â€“- that may contain arguments -- need to be identified: In many texts only certain sentences or paragraphs of the text are argumentative; the rest may be informative, for example providing context. In it's essence this is a binary classification task. Some approaches combine this task with the next and directly detect and classify the argument components~\cite{stabGurevych2017}. In this case the classifier is also tasked with detecting the type of component (e.g. conclusion, minor or major premise, etcetera depending on the structural model used.)

\paragraph{Segmentation} The identified parts need to be split into segments -- the task of component boundary detection -- where each segment may be a component in the final argument representation. Assuming that in a text about a court case the paragraphs containing the ruling and the reasoning behind it are identified, then this step splits that part into components (called argumentative discourse units~\cite{cohen1987} or elementary discourse units~\cite{saintDizier2012}) that can then be identified as the conclusion, premises, etc. This, again, is a classification task. This is implemented as a data-driven search for cue phrases (i.e. the words `because', `unless', but also words, word phrases and punctuation that are less explicit, or a complete analysis of the semantic structure) that indicate relations between text spans~\cite{mochales2011argumentation,saintDizier2012,lawrenceReed2015,stabGurevych2017}.

\paragraph{Prediction} The relations between the identified components need to be predicted. In this task the components are connected to each other to form the structure of the argument. This is the most challenging task as it requires insight in the meaning of a component to determine whether a premise component supports a certain claim component or whether it is related to another claim component. Some approaches also approach this as a binary classification task, testing each of the claim components in a certain defined order~\cite{cohen1987}. Others have a set of hand-coded rules that function as heuristic~\cite{saintDizier2012}. Another approach is to create a model that can determine the likeliness that two components are related and construct multiple scenarios to finally select the best overall scenario. Often knowledge about the domain is used to help in this task. For example, for some texts, such as procedures or didactic text, it can be assumed that a claim is always followed by one or more premises supporting that claim. In juristic texts certain marker words may signal the relations between components.

Most approaches are based on text which has been annotated using RST and a predefined set of schemas. The rules used in the three subtasks are, either by hand or automatically, derived from these previously annotated texts to create a model which can apply the same annotation to new texts.

\paragraph{Argumentation software}
Argumentation in Artificial Intelligence results in argumentation software, programs that often focus on understanding and teaching argumentation\cite{kirschnerEtal2003,scheuerEtal2010,noroozi2012argumentation}, as well as serve as a proof-of-concept of various formalisms,\cite{verheij2007}.

\paragraph{Our idea}
Our approach to understanding argumentative texts is based on a schematic representation of arguments in the form of boxes for claims and arrows for the support and attack relations between these claims \cite{peldszus2013argument,verheij2007}. Based on this schematic representation and its elements we define a grammar for a natural language on how to formulate these argumentative structures. Our human argumentative structure language (HASL) allows us to write argumentative text which can be directly interpreted as an argument diagram.

\paragraph{Goals}
Support and attack relations between arguments, warranted support in the form of general rules that support the step from premise to conclusion (i.e. major premise in syllogism). The ability to combine sentences to counter the need to restate premises (i.e. allow recursion). Anaphora resolution to avoid the need to restate the subjects. Enthymeme resolution to avoid the need to state many premises at all. 

\paragraph{Results}
For each of the basic building blocks for formal argumentation we define how these occur in our language, and how they can be differentiated form each other.

We implement these building blocks and their grammars into a larger grammar which allows us to create argumentative texts of multiple sentences. This language, the human argument structure language, or HASL for short, is explored in two variants.

We then test our implementation using the following examples:
\begin{exe}
	\ex\label{ex:socrates} Socrates is mortal because he is a man and men are mortal.
	\ex\label{ex:tweety} Tweety can fly because Tweety is a bird and birds can fly but Tweety is a penguin and penguins can not fly.
	\ex\label{ex:light} The object is red because the object appears red to me but it is illuminated by a red light.~\cite{pollock1987}
	\ex\label{ex:toulmin} Harry is a British subject because Harry was born in Bermuda and a man born in Bermuda is a British subject because of the following statutes and legal provisions but Harry has become a naturalized American.~\cite{toulmin1958}
\end{exe}

\paragraph{HASL}
Our experimental human argument structure language (HASL) implements a grammar for combining the building blocks by restating premises in multiple sentences. Each of the building blocks yields its own partial argument structure, which are merged at the sentence level to form the complete argument. This implementation does a complete parse of the premises themselves as well to differentiate between major and minor premises.

The grammar allows for nested argument structures: A premise that occurs on the right side of `because' can itself be the conclusion of a different part of the argument in the same sentence.

We implement a form of enthymeme resolution. Enthymemes, the occurrence of premises that are part of an argument but are not explicitly stated, occur often in natural language \cite{walton2005,reedRowe2004}. By filling in these missing premises in our argument graph we can make the right support or attack connections between premises, also when the targeted premise is not explicitly stated. We do this by treating building block around the attack and support relations as small syllogisms, and reconstruct the missing minor or major premise. The parsing of premises themselves, which is a part of HASL/1, provides the information necessary for the reconstruction.

We also implement pronominal anaphora resolution \cite{hobbs1978}. In HASL/1 premises that are the same are merged into a premise in our argument structure, and in HASL/1 we determine whether two premises are the same by comparing their text. When this text contains references to other parts of the argument, for example if the premise is `he has wings', we should also check whether `he' refers to the same object. Otherwise, premises that look the same but don't exactly mean the same are merged. Anaphora resolution helps us check this. By implementing this as part of the premise parser the reconstruction step of the enthymeme resolution can also profit from it.

\paragraph{Relevance}
HASL implements a form of argument mining, but ignores the difficult steps of being able to parse all of the English language. This allows us to explore what a complete understanding of the argumentative text entails, which argument mining is not yet able to explore \cite{stabGurevych2017}.

The implementations of HASL presented here can be used to gain a better understanding of complicated arguments, where there are many premises that interact with each other. Anaphora and enthymeme resolution help with further understanding of the argument.

The language of HASL itself can be used to a new type of interface to the reasoning process of computer programs, allowing for the explanation of the reasoning behind a conclusion, or even for interactive partaking.

\section{HASL}
\input{hasl}

\section{Evaluation: syllogisms and Toulmin arguments}
\input{evaluation}


\section{Discussion of related research}
\input{discussion}

\section{Conclusion}
\input{conclusion}

%
%Diagramming tools (Araucaria, Reason!Able, ArguMed)
%
%Text analysis assistants (Araucaria)
%
%Argument mining
%
%Logical languages (with evaluation)
%
%
%\section{Translating natural language arguments to argument diagrams, and back}
%
%Description of how it all works
%
%(Elementary, representative examples)
%
%\section{Toulmin's diagram}
%
%
%\section{Assessment}
%
%Interesting examples
%
%Things that go wrong!



\bibliographystyle{plain}
\bibliography{cumulative}

\end{document}

